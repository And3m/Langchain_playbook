"""
Helper utilities for LangChain Playbook.
"""

import time\nimport asyncio\nfrom functools import wraps\nfrom typing import Any, Callable, TypeVar, Optional\nfrom .logging import get_logger\n\nlogger = get_logger(__name__)\n\nF = TypeVar('F', bound=Callable[..., Any])\n\n\ndef timing_decorator(func: F) -> F:\n    \"\"\"Decorator to measure function execution time.\n    \n    Args:\n        func: Function to measure\n        \n    Returns:\n        Wrapped function that logs execution time\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        try:\n            result = func(*args, **kwargs)\n            execution_time = time.time() - start_time\n            logger.info(f\"{func.__name__} executed in {execution_time:.2f} seconds\")\n            return result\n        except Exception as e:\n            execution_time = time.time() - start_time\n            logger.error(f\"{func.__name__} failed after {execution_time:.2f} seconds: {e}\")\n            raise\n    \n    return wrapper\n\n\ndef async_timing_decorator(func: F) -> F:\n    \"\"\"Decorator to measure async function execution time.\n    \n    Args:\n        func: Async function to measure\n        \n    Returns:\n        Wrapped async function that logs execution time\n    \"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        start_time = time.time()\n        try:\n            result = await func(*args, **kwargs)\n            execution_time = time.time() - start_time\n            logger.info(f\"{func.__name__} executed in {execution_time:.2f} seconds\")\n            return result\n        except Exception as e:\n            execution_time = time.time() - start_time\n            logger.error(f\"{func.__name__} failed after {execution_time:.2f} seconds: {e}\")\n            raise\n    \n    return wrapper\n\n\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \"...\") -> str:\n    \"\"\"Truncate text to a maximum length.\n    \n    Args:\n        text: Text to truncate\n        max_length: Maximum length\n        suffix: Suffix to add when truncating\n        \n    Returns:\n        Truncated text\n    \"\"\"\n    if len(text) <= max_length:\n        return text\n    return text[:max_length - len(suffix)] + suffix\n\n\ndef safe_get(dictionary: dict, key: str, default: Any = None) -> Any:\n    \"\"\"Safely get a value from a dictionary.\n    \n    Args:\n        dictionary: Dictionary to get value from\n        key: Key to look up\n        default: Default value if key not found\n        \n    Returns:\n        Value from dictionary or default\n    \"\"\"\n    try:\n        return dictionary[key]\n    except (KeyError, TypeError):\n        return default\n\n\ndef format_tokens(tokens: int) -> str:\n    \"\"\"Format token count in a human-readable way.\n    \n    Args:\n        tokens: Number of tokens\n        \n    Returns:\n        Formatted token count\n    \"\"\"\n    if tokens < 1000:\n        return f\"{tokens} tokens\"\n    elif tokens < 1000000:\n        return f\"{tokens/1000:.1f}K tokens\"\n    else:\n        return f\"{tokens/1000000:.1f}M tokens\"\n\n\ndef estimate_cost(tokens: int, model: str = \"gpt-3.5-turbo\") -> float:\n    \"\"\"Estimate cost for token usage.\n    \n    Args:\n        tokens: Number of tokens\n        model: Model name\n        \n    Returns:\n        Estimated cost in USD\n    \"\"\"\n    # Rough pricing estimates (as of 2024)\n    pricing = {\n        \"gpt-3.5-turbo\": 0.0015 / 1000,  # $0.0015 per 1K tokens\n        \"gpt-4\": 0.03 / 1000,            # $0.03 per 1K tokens\n        \"gpt-4-turbo\": 0.01 / 1000,      # $0.01 per 1K tokens\n        \"claude-3-haiku\": 0.00025 / 1000, # $0.00025 per 1K tokens\n        \"claude-3-sonnet\": 0.003 / 1000,  # $0.003 per 1K tokens\n        \"claude-3-opus\": 0.015 / 1000,    # $0.015 per 1K tokens\n    }\n    \n    price_per_token = pricing.get(model, 0.002 / 1000)  # Default fallback\n    return tokens * price_per_token\n\n\ndef batch_process(items: list, batch_size: int = 10) -> list:\n    \"\"\"Process items in batches.\n    \n    Args:\n        items: List of items to process\n        batch_size: Size of each batch\n        \n    Returns:\n        List of batches\n    \"\"\"\n    batches = []\n    for i in range(0, len(items), batch_size):\n        batches.append(items[i:i + batch_size])\n    return batches\n\n\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\n    \"\"\"Decorator for retrying functions with exponential backoff.\n    \n    Args:\n        max_retries: Maximum number of retries\n        base_delay: Base delay in seconds\n        \n    Returns:\n        Decorator function\n    \"\"\"\n    def decorator(func: F) -> F:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_retries + 1):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    if attempt == max_retries:\n                        logger.error(f\"{func.__name__} failed after {max_retries} retries: {e}\")\n                        raise\n                    \n                    delay = base_delay * (2 ** attempt)\n                    logger.warning(f\"{func.__name__} failed (attempt {attempt + 1}), retrying in {delay}s: {e}\")\n                    time.sleep(delay)\n        \n        return wrapper\n    return decorator